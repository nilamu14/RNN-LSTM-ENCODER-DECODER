{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to load dataset\n",
    "import numpy as np     # for mathematic equation\n",
    "from nltk.corpus import stopwords   # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/gdrive/MyDrive/IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee5c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee89777",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('/content/gdrive/MyDrive/IMDB.csv')\n",
    "    x_data = df['review']\n",
    "    y_data = df['sentiment']\n",
    "    x_data = x_data.replace({'<.*?>':''},regex=True)\n",
    "    x_data = x_data.replace({'[^A-Za-z]':' '},regex = True)\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])\n",
    "    \n",
    "    # ENCODE SENTIMENT -> 0 & 1\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "    \n",
    "    return x_data, y_data\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf946b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac91bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa672a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "  review_length = []\n",
    "  for review in x_train:\n",
    "     review_length.append(len(review))\n",
    "  return int(np.ceil(np.mean(review_length))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize and pad/Truncate Reviews \n",
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "max_length = get_max_length()\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e76e9",
   "metadata": {},
   "source": [
    "Build Architecture/Model Embedding Layer: in simple terms, it creates word vectors of each word in the word_index and group words that are related or have similar meaning by analyzing other words around them.\n",
    "\n",
    "LSTM Layer: to make a decision to keep or throw away data by considering the current input, previous output, and previous memory. There are some important components in LSTM.\n",
    "\n",
    "Forget Gate, decides information is to be kept or thrown away Input Gate, updates cell state by passing previous output and current input into sigmoid activation function Cell State, calculate new cell state, it is multiplied by forget vector (drop value if multiplied by a near 0), add it with the output from input gate to update the cell state value. Ouput Gate, decides the next hidden state and used for predictions Dense Layer: compute the input with the weight matrix and bias (optional), and using an activation function. I use Sigmoid activation function for this work because the output is only 0 or 1.\n",
    "\n",
    "The optimizer is Adam and the loss function is Binary Crossentropy because again the output is only 0 and 1, which is a binary number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6325b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y == y_pred[i]:\n",
    "        true += 1\n",
    "print('Correct Prediction: {}'.format(true))\n",
    "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
    "print('Accuracy: {}'.format(true/len(y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721038a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = str(input('Movie Review: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83aed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process input\n",
    "regex = re.compile(r'[^a-zA-Z\\s]')\n",
    "review = regex.sub('', review)\n",
    "print('Cleaned: ', review)\n",
    "\n",
    "words = review.split(' ')\n",
    "filtered = [w for w in words if w not in english_stops]\n",
    "filtered = ' '.join(filtered)\n",
    "filtered = [filtered.lower()]\n",
    "\n",
    "print('Filtered: ', filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922809e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_words = token.texts_to_sequences(filtered)\n",
    "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
    "print(tokenize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b271aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_model.predict(tokenize_words)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
